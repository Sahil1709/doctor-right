{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnan, when, count, countDistinct\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/23 16:19:40 WARN Utils: Your hostname, sahils-MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 10.10.15.90 instead (on interface en0)\n",
      "24/09/23 16:19:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/23 16:19:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/23 16:19:54 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"EDA on Mips Procedure Volume Data\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NPI: integer (nullable = true)\n",
      " |-- Ind_PAC_ID: long (nullable = true)\n",
      " |-- Provider_Last_Name: string (nullable = true)\n",
      " |-- Provider_First_Name: string (nullable = true)\n",
      " |-- Provider_Middle_Name: string (nullable = true)\n",
      " |-- suff: string (nullable = true)\n",
      " |-- Procedure_Category: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      " |-- Percentile: integer (nullable = true)\n",
      " |-- Profile_Display_Indicator: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"sample-data/doctorright-datalake/hive_metastore.mips_data.procedurevolume.parquet\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/23 16:30:03 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------------------+-------------------+--------------------+----+------------------+------------------+------------------+-------------------------+\n",
      "|summary|                 NPI|          Ind_PAC_ID|Provider_Last_Name|Provider_First_Name|Provider_Middle_Name|suff|Procedure_Category|             Count|        Percentile|Profile_Display_Indicator|\n",
      "+-------+--------------------+--------------------+------------------+-------------------+--------------------+----+------------------+------------------+------------------+-------------------------+\n",
      "|  count|              146830|              146830|            146830|             146830|              105553|4357|            146830|            146830|             84471|                   146830|\n",
      "|   mean|1.4990020628288293E9| 4.989287104569938E9|               NaN|                NaN|                NULL|NULL|              NULL|119.69468811781559| 67.60664606788129|                     NULL|\n",
      "| stddev| 2.874875257791035E8|2.8744089953311486E9|              NULL|                NaN|                NULL|NULL|              NULL| 202.7462586896489|20.336223514856183|                     NULL|\n",
      "|    min|          1003000480|            42100026|            AABERG|                  A|                   A|   I|  Cataract surgery|              1-10|                22|                        N|\n",
      "|    max|          1992999817|          9931596061|           ZYWICKE|            ZYGMUNT|           ZWYCEWICZ|  VI|     Spinal fusion|               999|                99|                        Y|\n",
      "+-------+--------------------+--------------------+------------------+-------------------+--------------------+----+------------------+------------------+------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:===================>                                       (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------------+-------------------+--------------------+------+------------------+-----+----------+-------------------------+\n",
      "|NPI|Ind_PAC_ID|Provider_Last_Name|Provider_First_Name|Provider_Middle_Name|  suff|Procedure_Category|Count|Percentile|Profile_Display_Indicator|\n",
      "+---+----------+------------------+-------------------+--------------------+------+------------------+-----+----------+-------------------------+\n",
      "|  0|         0|                 1|                  5|               41277|142473|                 0|    0|     62359|                        0|\n",
      "+---+----------+------------------+-------------------+--------------------+------+------------------+-----+----------+-------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NPI', 'int'),\n",
       " ('Ind_PAC_ID', 'bigint'),\n",
       " ('Provider_Last_Name', 'string'),\n",
       " ('Provider_First_Name', 'string'),\n",
       " ('Provider_Middle_Name', 'string'),\n",
       " ('suff', 'string'),\n",
       " ('Procedure_Category', 'string'),\n",
       " ('Count', 'string'),\n",
       " ('Percentile', 'int'),\n",
       " ('Profile_Display_Indicator', 'string')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
